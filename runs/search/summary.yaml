architectures:
- architecture:
    name: mlp_3x_252x32x16
    layers:
    - 252
    - 32
    - 16
  best_validation_loss: 0.09136837371587753
  test_loss_stats:
    mean: 0.08476113968372345
    var: 5.814857616808167e-06
    min: 0.0812172233581543
    max: 0.08733116456270218
- architecture:
    name: mlp_3x_192x126x64
    layers:
    - 192
    - 126
    - 64
  best_validation_loss: 0.07731628079414368
  test_loss_stats:
    mean: 0.07702184605360031
    var: 4.522489212766577e-06
    min: 0.07287386833429337
    max: 0.07861412553787231
- architecture:
    name: mlp_3x_126x126x126
    layers:
    - 126
    - 126
    - 126
  best_validation_loss: 0.08155428149700165
  test_loss_stats:
    mean: 0.07969758518695831
    var: 1.5797127077760884e-06
    min: 0.07857645694017411
    max: 0.08207383307218552
- architecture:
    name: mlp_3x_286x16x16
    layers:
    - 286
    - 16
    - 16
  best_validation_loss: 0.09070520352125168
  test_loss_stats:
    mean: 0.08859651385307313
    var: 4.710203995849503e-06
    min: 0.08487039625644684
    max: 0.09068019704818725
